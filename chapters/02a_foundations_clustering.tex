
%
% foundations - clustering
%

\section{Clustering and maps}

A common use case in web mapping is representing markers on a slippy map.Markers are the most simple and common geometric features that visualize vector data information on maps. Publicly available services like OpenStreetMap or Google Maps allow a broader audience to create interactive maps that tell stories in a visual way.

Visualizing thousands of markers on a single map are both challenges to human and digital computability. Obviously, when telling a story information needs to be told in a compact way. The human brain can only process a limited amount of data at the same time. Similarly, large amounts of data involve a higher burden on the computer components that participate in the web mapping process.

An exemplary scenario for visualizing data on a map and the involved components is illustrated in Figure x (TODO):

1. A client requests the server to display a map.
2. The server receives and understands the request.
3. The server fetches the map data from the database.
4. The server delivers the map data and further markup to the client.
5. The client receives the map data with the markup.
6. A javascript library visualizes the map data on a map.

The important part from a performance perspective is that the whole data that is visualized on the client first needs to be fetched, processed and delivered by the server. Next, the client also receives all the data and visualizes it on its own using a javascript library. (TODO Reference chapter) Thus, large amounts of map data do not only mean more visual information to process for the user. They also have negative impact on performance on the involved components from server to client. As a result, this means slower response times. 

The task of clustering geospatial data for slippy maps on a per-request basis requires a performance-optimized approach that works in real-time. Details on this decision are explained in (TODOREF). Given these assumptions, this thesis touches clustering as a research discipline only on the surface. Though, an overview of the fundamental concepts for cluster analysis should be given to provide context for the decisions to be made.

\section{Clustering}

Clustering is the task of grouping unlabeled data in an automated way. It can also be described as the unsupervised classification of patterns into groups. TODO CHAPTER OVERVIEW

The techniques of cluster analysis are applied in numerous scenarios including data mining, document retrieval, image segmentation and pattern classification. They are used to solve different tasks including pattern-analysis, grouping, decision-making or machine-learning.

Cluster analysis has been studied since the early beginnings of computer science and applies to a broad number of research fields. Different research communities have created a variety of vocabularies to describe methods related to clustering. Analog to the term cluster analysis, other names are used in literature: Q-analysis, topology, grouping, comping, classification, numerical taxonomy and unsupervised pattern recognition.

As indicated, clustering is a wide and generic term. Often it is used to refer to specific concepts which are appropriate for solving specific tasks. This means that efficient clustering algorithms have been developed and studied over the years for certain research fields. While such algorithms might perform well under certain circumstances, they might be completely inappropriate for other use cases. Imagine, an algorithm that  fits image segmentation well but is less useful in machine-learning \cite{Meert06clustermaps, Jain99clusterreview}. 


\subsection{The Clustering task}

Clustering is the task of aggregating items (also described as features) into clusters, based on similarities or proximity.

A.K. Jain, M.N. Murty and P.J. Flynn \cite{Jain99clusterreview} define the following steps involved in a typical pattern clustering activity:
 
\begin{quote}
\begin{enumerate}
\item pattern representation (optionally including feature extraction and/or selection), 
\item definition of a pattern proximity measure appropriate to the data domain, 
\item clustering or grouping, 
\item data abstraction (if needed), and 
\item assessment of output (if needed). 
\end{enumerate}
\end{quote}

\subsection{History}

K-means, one of the oldest and most widely used clustering algorithm was introduced already in 1967 \cite{MacQueen67kmeans, Meert06clustermaps}. Tryon and Bailey (1970) wrote one of the first books on cluster analysis. In 1973, Anderberg published "Cluster analysis for applications", a book that Jain and Dubes describe as "the most comprehensive book for those who want to use cluster analysis." \cite{Jain88clustering} While Tryon and Bailey focus on a single clustering approach (BC TRY), Anderberg already gives a comprehensive overview of clustering methods, strategies and a comparative evaluation of cluster analysis methods.

Clustering algorithms where improved and developed further over time, i.e. to account for performance issues. Prominent algorithms in that area include CLARANS \cite{Ng94CLARANS} and BIRCH \cite{Zhang96BIRCH} which have a time complexity linear in the number of patterns. A popular, density based clustering algorithm is DBSCAN \cite{Ester96DBSCAN}.

Jain and Dubes summarize hierarchical and partitional clustering approaches in "Algorithms for Clustering Data" (1988) with a special focus on applications in image processing. Numerous, subsequent publications on cluster analysis are released continuously. \cite{Jain99clusterreview}

TODO: Add information about clustering history for 200x.  

